{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mhose\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, GlobalAveragePooling1D, Dropout, LayerNormalization, MultiHeadAttention\n",
    "from tensorflow.keras.layers import Layer, GRU, Bidirectional, Dense, Input, Reshape, GlobalAveragePooling1D\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...</td>\n",
       "      <td>other</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...</td>\n",
       "      <td>team</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>বাংলাদেশের পরে ভারতের সাপর্ট ই করি ?</td>\n",
       "      <td>team</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>সৌম্যকে বাদ দেওয়া হোক</td>\n",
       "      <td>batting</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>প্রথমটি হচ্ছে, কোচ অত:পর সাকিব,সাকিব আর সাকিবর...</td>\n",
       "      <td>team</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 1                                               Text  \\\n",
       "0         NaN         NaN  জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...   \n",
       "1         NaN         NaN  জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...   \n",
       "2         NaN         NaN               বাংলাদেশের পরে ভারতের সাপর্ট ই করি ?   \n",
       "3         NaN         NaN                              সৌম্যকে বাদ দেওয়া হোক   \n",
       "4         NaN         NaN  প্রথমটি হচ্ছে, কোচ অত:পর সাকিব,সাকিব আর সাকিবর...   \n",
       "\n",
       "  Category  Polarity  \n",
       "0    other  positive  \n",
       "1     team  positive  \n",
       "2     team  positive  \n",
       "3  batting  negative  \n",
       "4     team  positive  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"F:\\MTL Cyberbullying\\Cricket - Sheet1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...</td>\n",
       "      <td>other</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...</td>\n",
       "      <td>team</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>বাংলাদেশের পরে ভারতের সাপর্ট ই করি ?</td>\n",
       "      <td>team</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>সৌম্যকে বাদ দেওয়া হোক</td>\n",
       "      <td>batting</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>প্রথমটি হচ্ছে, কোচ অত:পর সাকিব,সাকিব আর সাকিবর...</td>\n",
       "      <td>team</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Category  Polarity\n",
       "0  জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...    other  positive\n",
       "1  জয় বাংলা কাপ! তাও আবার স্বাধীনতার মাস মার্চে। ...     team  positive\n",
       "2               বাংলাদেশের পরে ভারতের সাপর্ট ই করি ?     team  positive\n",
       "3                              সৌম্যকে বাদ দেওয়া হোক  batting  negative\n",
       "4  প্রথমটি হচ্ছে, কোচ অত:পর সাকিব,সাকিব আর সাকিবর...     team  positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['Text', 'Category', 'Polarity']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "other              1010\n",
       "team                731\n",
       "batting             580\n",
       "team management     329\n",
       "bowling             329\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Polarity\n",
       "negative    2152\n",
       "positive     566\n",
       "neutral      261\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>জয় বাংলা কাপ স্বাধীনতার মাস মার্চে মাথা চমৎকার...</td>\n",
       "      <td>other</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>জয় বাংলা কাপ স্বাধীনতার মাস মার্চে মাথা চমৎকার...</td>\n",
       "      <td>team</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>বাংলাদেশের ভারতের সাপর্ট</td>\n",
       "      <td>team</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>সৌম্যকে বাদ</td>\n",
       "      <td>batting</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>প্রথমটি কোচ অতপর সাকিবসাকিব সাকিবরে দলে</td>\n",
       "      <td>team</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Category  Polarity\n",
       "0  জয় বাংলা কাপ স্বাধীনতার মাস মার্চে মাথা চমৎকার...    other  positive\n",
       "1  জয় বাংলা কাপ স্বাধীনতার মাস মার্চে মাথা চমৎকার...     team  positive\n",
       "2                           বাংলাদেশের ভারতের সাপর্ট     team  positive\n",
       "3                                        সৌম্যকে বাদ  batting  negative\n",
       "4            প্রথমটি কোচ অতপর সাকিবসাকিব সাকিবরে দলে     team  positive"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize Bengali stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('bengali'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\s]', '', text)  # Keep only Bengali characters\n",
    "    text = re.sub(r'\\d+', '', text)                 # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()        # Remove extra spaces\n",
    "\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Mini Conda\\envs\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the pre-trained tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('sagorsarker/bangla-bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text        0\n",
      "Category    0\n",
      "Polarity    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify that there are no more null values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: (2979, 128)\n",
      "Attention masks shape: (2979, 128)\n",
      "Label 1 (Category) shape: (2979,)\n",
      "Label 2 (Polarity) shape: (2979,)\n"
     ]
    }
   ],
   "source": [
    "# Define a function to tokenize a single sentence\n",
    "def tokenize_data(df, max_length=128):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for sentence in df['Text']:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True, \n",
    "            max_length=max_length,    \n",
    "            padding='max_length',    \n",
    "            truncation=True,           \n",
    "            return_attention_mask=True, \n",
    "            return_tensors='tf'        \n",
    "        )\n",
    "        \n",
    "        # Append to lists\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "    # Convert lists to tensors\n",
    "    input_ids = tf.convert_to_tensor(input_ids)\n",
    "    attention_masks = tf.convert_to_tensor(attention_masks)\n",
    "    \n",
    "    # Squeeze the extra dimension\n",
    "    input_ids = tf.squeeze(input_ids, axis=1)\n",
    "    attention_masks = tf.squeeze(attention_masks, axis=1)\n",
    "    \n",
    "    return input_ids, attention_masks\n",
    "\n",
    "input_ids, attention_masks = tokenize_data(df)\n",
    "\n",
    "label_1 = tf.convert_to_tensor(df['Category'])\n",
    "label_2 = tf.convert_to_tensor(df['Polarity'])\n",
    "\n",
    "print(f\"Input IDs shape: {input_ids.shape}\")\n",
    "print(f\"Attention masks shape: {attention_masks.shape}\")\n",
    "print(f\"Label 1 (Category) shape: {label_1.shape}\")\n",
    "print(f\"Label 2 (Polarity) shape: {label_2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure input_ids and attention_masks are converted to integer type tensors\n",
    "input_ids = tf.convert_to_tensor(input_ids, dtype=tf.int32)\n",
    "attention_masks = tf.convert_to_tensor(attention_masks, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize label encoders for the string labels\n",
    "label_encoder_1 = LabelEncoder()\n",
    "label_encoder_2 = LabelEncoder()\n",
    "\n",
    "# Encode string labels into integers\n",
    "df['Category'] = label_encoder_1.fit_transform(df['Category'])\n",
    "df['Polarity'] = label_encoder_2.fit_transform(df['Polarity'])\n",
    "\n",
    "# Convert labels to TensorFlow tensors\n",
    "label_1 = tf.convert_to_tensor(df['Category'], dtype=tf.int32)\n",
    "label_2 = tf.convert_to_tensor(df['Polarity'], dtype=tf.int32)\n",
    "\n",
    "# Ensure input_ids and attention_masks are correctly formatted as tensors\n",
    "input_ids = tf.convert_to_tensor(input_ids, dtype=tf.int32)\n",
    "attention_masks = tf.convert_to_tensor(attention_masks, dtype=tf.int32)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, att_mask_train, att_mask_test, y_cat_train, y_cat_test, y_gender_train, y_gender_test = train_test_split(\n",
    "    input_ids.numpy(), attention_masks.numpy(),\n",
    "    label_1.numpy(), label_2.numpy(),  \n",
    "    test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 128, 128)     13052800    ['input_ids[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 128, 256)     263168      ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 128)         164352      ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           8256        ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_masks (InputLayer)   [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " Category (Dense)               (None, 5)            325         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Polarity (Dense)               (None, 3)            195         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,489,096\n",
      "Trainable params: 13,489,096\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_bilstm_model(input_shape):\n",
    "    input_ids = tf.keras.layers.Input(shape=(input_shape,), dtype='int32', name='input_ids')\n",
    "    attention_masks = tf.keras.layers.Input(shape=(input_shape,), dtype='int32', name='attention_masks')\n",
    "\n",
    "    # Embedding layer\n",
    "    embedding_layer = tf.keras.layers.Embedding(input_dim=tokenizer.vocab_size, output_dim=128)(input_ids)\n",
    "\n",
    "    # First BiLSTM layer with dropout\n",
    "    lstm_output = tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.3))(embedding_layer)\n",
    "\n",
    "    # Second BiLSTM layer\n",
    "    lstm_output_2 = tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(64, return_sequences=False, dropout=0.3))(lstm_output)\n",
    "\n",
    "    # Dense layer before output layers\n",
    "    dense_layer = tf.keras.layers.Dense(64, activation='relu')(lstm_output_2)\n",
    "\n",
    "    # Dropout layer for regularization\n",
    "    dropout_layer = tf.keras.layers.Dropout(0.3)(dense_layer)\n",
    "\n",
    "    # Output layers for multi-task learning\n",
    "    output_category = tf.keras.layers.Dense(5, activation='softmax', name='Category')(dropout_layer)\n",
    "    output_polarity = tf.keras.layers.Dense(3, activation='softmax', name='Polarity')(dropout_layer)\n",
    "\n",
    "    # Define the model with inputs and outputs\n",
    "    model = tf.keras.Model(inputs=[input_ids, attention_masks],\n",
    "                           outputs=[output_category, output_polarity])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the BiLSTM model\n",
    "bilstm_model = create_bilstm_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "bilstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'Category': 'sparse_categorical_crossentropy', 'Polarity': 'sparse_categorical_crossentropy'},\n",
    "    metrics={'Category': 'accuracy', 'Polarity': 'accuracy'}\n",
    ")\n",
    "\n",
    "# Display the model summary\n",
    "bilstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "67/67 [==============================] - 20s 80ms/step - loss: 2.3982 - Category_loss: 1.5661 - Polarity_loss: 0.8321 - Category_accuracy: 0.2957 - Polarity_accuracy: 0.7094 - val_loss: 2.2652 - val_Category_loss: 1.4758 - val_Polarity_loss: 0.7895 - val_Category_accuracy: 0.4351 - val_Polarity_accuracy: 0.7071\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 4s 58ms/step - loss: 2.1308 - Category_loss: 1.4037 - Polarity_loss: 0.7271 - Category_accuracy: 0.4118 - Polarity_accuracy: 0.7355 - val_loss: 1.9988 - val_Category_loss: 1.2871 - val_Polarity_loss: 0.7117 - val_Category_accuracy: 0.4854 - val_Polarity_accuracy: 0.7490\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 4s 58ms/step - loss: 1.7191 - Category_loss: 1.1083 - Polarity_loss: 0.6108 - Category_accuracy: 0.5429 - Polarity_accuracy: 0.7626 - val_loss: 2.0150 - val_Category_loss: 1.3259 - val_Polarity_loss: 0.6891 - val_Category_accuracy: 0.4603 - val_Polarity_accuracy: 0.7531\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 4s 58ms/step - loss: 1.3815 - Category_loss: 0.8626 - Polarity_loss: 0.5189 - Category_accuracy: 0.6754 - Polarity_accuracy: 0.8018 - val_loss: 2.0885 - val_Category_loss: 1.3284 - val_Polarity_loss: 0.7601 - val_Category_accuracy: 0.4854 - val_Polarity_accuracy: 0.7573\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 4s 58ms/step - loss: 1.1236 - Category_loss: 0.6724 - Polarity_loss: 0.4512 - Category_accuracy: 0.7561 - Polarity_accuracy: 0.8162 - val_loss: 2.3275 - val_Category_loss: 1.5085 - val_Polarity_loss: 0.8190 - val_Category_accuracy: 0.5146 - val_Polarity_accuracy: 0.7280\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "         \n",
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=3,       \n",
    "    restore_best_weights=True \n",
    ")\n",
    "\n",
    "# Train the model with EarlyStopping\n",
    "history = bilstm_model.fit(\n",
    "    [X_train, att_mask_train], \n",
    "    {'Category': y_cat_train, 'Polarity': y_gender_train}, \n",
    "    validation_split=0.1,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping]  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 36ms/step - loss: 2.0275 - Category_loss: 1.3242 - Polarity_loss: 0.7034 - Category_accuracy: 0.4513 - Polarity_accuracy: 0.7265\n",
      "Test Loss and Accuracy: [2.027545928955078, 1.3241503238677979, 0.7033955454826355, 0.45134228467941284, 0.7265100479125977]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "results = bilstm_model.evaluate(\n",
    "    [X_test, att_mask_test],\n",
    "    {'Category': y_cat_test, 'Polarity': y_gender_test}\n",
    ")\n",
    "\n",
    "print(f\"Test Loss and Accuracy: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 27ms/step\n",
      "Classification Report for Category:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.56      0.45       117\n",
      "           1       0.42      0.56      0.48        62\n",
      "           2       0.51      0.76      0.61       209\n",
      "           3       0.37      0.07      0.12       146\n",
      "           4       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.45       596\n",
      "   macro avg       0.33      0.39      0.33       596\n",
      "weighted avg       0.39      0.45      0.38       596\n",
      "\n",
      "\n",
      "Classification Report for Polarity:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       433\n",
      "           1       0.00      0.00      0.00        45\n",
      "           2       0.46      0.43      0.45       118\n",
      "\n",
      "    accuracy                           0.73       596\n",
      "   macro avg       0.42      0.44      0.43       596\n",
      "weighted avg       0.66      0.73      0.69       596\n",
      "\n",
      "\n",
      "Macro-Averaged Scores for Category:\n",
      "Precision: 0.3346, Recall: 0.3906, F1 Score: 0.3311\n",
      "\n",
      "Macro-Averaged Scores for Polarity:\n",
      "Precision: 0.4157, Recall: 0.4381, F1 Score: 0.4259\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Get Predictions\n",
    "predictions = bilstm_model.predict([X_test, att_mask_test])\n",
    "\n",
    "# Step 2: Convert predictions to class labels\n",
    "y_cat_pred = np.argmax(predictions[0], axis=1)   # 'Category' prediction\n",
    "y_gender_pred = np.argmax(predictions[1], axis=1)  # 'Polarity' prediction\n",
    "\n",
    "# Step 3: Generate Classification Report with zero_division specified\n",
    "# For Category\n",
    "print(\"Classification Report for Category:\")\n",
    "print(classification_report(y_cat_test, y_cat_pred, zero_division=0))\n",
    "\n",
    "# For Polarity\n",
    "print(\"\\nClassification Report for Polarity:\")\n",
    "print(classification_report(y_gender_test, y_gender_pred, zero_division=0))\n",
    "\n",
    "# If you want the macro-averaged precision, recall, and F1 scores separately:\n",
    "cat_precision = precision_score(y_cat_test, y_cat_pred, average='macro', zero_division=0)\n",
    "cat_recall = recall_score(y_cat_test, y_cat_pred, average='macro', zero_division=0)\n",
    "cat_f1 = f1_score(y_cat_test, y_cat_pred, average='macro', zero_division=0)\n",
    "\n",
    "gender_precision = precision_score(y_gender_test, y_gender_pred, average='macro', zero_division=0)\n",
    "gender_recall = recall_score(y_gender_test, y_gender_pred, average='macro', zero_division=0)\n",
    "gender_f1 = f1_score(y_gender_test, y_gender_pred, average='macro', zero_division=0)\n",
    "\n",
    "print(\"\\nMacro-Averaged Scores for Category:\")\n",
    "print(f\"Precision: {cat_precision:.4f}, Recall: {cat_recall:.4f}, F1 Score: {cat_f1:.4f}\")\n",
    "\n",
    "print(\"\\nMacro-Averaged Scores for Polarity:\")\n",
    "print(f\"Precision: {gender_precision:.4f}, Recall: {gender_recall:.4f}, F1 Score: {gender_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
